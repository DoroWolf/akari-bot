# https://toml.io/en/v1.0.0
# NOTE: TOML is not like Python. Do not use Python syntax here.
# EXAMPLE: Boolean values in TOML must be lowercase.

[module_ai]
# The basic config section of the module. The value ​​filled in here can be displayed in the message. Please do not fill in sensitive information in this section.
llm_max_tokens = 4096 # Limit the maximum number of tokens for LLMs.
llm_temperature = 1 # The sampling temperature of the LLMs, ranging from 0-2. It is not recommended to modify it at the same time as top_p.
llm_top_p = 1 # The karnel sampling of the LLM, ranging from 0-1. It is not recommended to modify it at the same time as temperature.
ai_default_llm = "<Replace me with str value>" # The LLM used by default.
anthropic_api_url = "<Replace me with str value>" # API address of Anthropic API. (For ai module)
deepseek_api_url = "<Replace me with str value>" # API address of DeepSeek API. (For ai module)
openai_api_url = "<Replace me with str value>" # API address of OpenAI API. (For ai module)

[module_ai_secret]
# The secret config section of the module. The bot will try to intercept if the value here accidentally appears in the message sent, but be careful to prevent leakage.
anthropic_api_key = "<Replace me with str value>" # Anthropic API Key. (For ai module)
deepseek_api_key = "<Replace me with str value>" # DeepSeek API Key. (For ai module)
openai_api_key = "<Replace me with str value>" # OpenAI API Key. (For ai module)
